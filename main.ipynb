{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c5c8309",
   "metadata": {},
   "source": [
    "STEP 1 : OUTPUT A CSV CONTAINING ALL USERS SUSPECTED FOR ABUSE USING RAPID FUZZ LOGIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280cb397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished. Matches found: 2847\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import fuzz\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv(\"example_input_data.csv\")  # Replace with your file path\n",
    "\n",
    "# --- Address Normalization ---\n",
    "def normalize_address(addr):\n",
    "    addr = str(addr).lower()\n",
    "    \n",
    "    # Replace common abbreviations\n",
    "    addr = re.sub(r\"\\bflat\\s*no\\b|\\bflat\\b\", \"flat\", addr)\n",
    "    addr = re.sub(r\"\\btower\\b|\\bblock\\b\", \"tower\", addr)\n",
    "    addr = re.sub(r\"\\bsec\\b|\\bsector\\b\", \"sector\", addr)\n",
    "    addr = re.sub(r\"\\bfloor\\b\", \"floor\", addr)\n",
    "    addr = re.sub(r\"\\bapt\\b|\\bapartment\\b\", \"apartment\", addr)\n",
    "\n",
    "    # Remove all punctuation except numbers/letters/space\n",
    "    addr = re.sub(r\"[^a-z0-9\\s]\", \" \", addr)\n",
    "    addr = re.sub(r\"\\s+\", \" \", addr).strip()  # collapse multiple spaces\n",
    "    return addr\n",
    "\n",
    "# --- Name Normalization ---\n",
    "def normalize_name(name):\n",
    "    name = str(name).lower()\n",
    "    name = re.sub(r\"[^a-z\\s]\", \"\", name)  # remove punctuation/numbers\n",
    "    name = re.sub(r\"\\s+\", \" \", name).strip()\n",
    "    return name\n",
    "\n",
    "df[\"normalized_address\"] = df[\"full_address\"].apply(normalize_address)\n",
    "df[\"normalized_name\"] = df[\"customer_name\"].apply(normalize_name)\n",
    "\n",
    "# Group by locality\n",
    "grouped = df.groupby(\"locality\")\n",
    "\n",
    "# Thresholds\n",
    "ADDRESS_SIMILARITY_THRESHOLD = 88\n",
    "NAME_SIMILARITY_THRESHOLD = 70  # a bit relaxed due to improved preprocessing\n",
    "\n",
    "# Track seen pairs\n",
    "already_seen_pairs = set()\n",
    "results = []\n",
    "\n",
    "# Comparison function\n",
    "def is_potential_duplicate(addr1, addr2, name1, name2):\n",
    "    addr_score = fuzz.token_sort_ratio(addr1, addr2)\n",
    "    name_score = fuzz.partial_ratio(name1, name2)\n",
    "    return addr_score >= ADDRESS_SIMILARITY_THRESHOLD and name_score >= NAME_SIMILARITY_THRESHOLD\n",
    "\n",
    "# Main loop\n",
    "for locality, group in grouped:\n",
    "    records = group.to_dict(orient=\"records\")\n",
    "    \n",
    "    for a, b in itertools.combinations(records, 2):\n",
    "        id_a, id_b = str(a[\"customer\"]), str(b[\"customer\"])\n",
    "        primary_id, secondary_id = sorted([id_a, id_b])\n",
    "\n",
    "        pair_key = (primary_id, secondary_id)\n",
    "        if pair_key in already_seen_pairs:\n",
    "            continue\n",
    "\n",
    "        if is_potential_duplicate(a[\"normalized_address\"], b[\"normalized_address\"],\n",
    "                                  a[\"normalized_name\"], b[\"normalized_name\"]):\n",
    "            if id_a == primary_id:\n",
    "                primary_rec, secondary_rec = a, b\n",
    "            else:\n",
    "                primary_rec, secondary_rec = b, a\n",
    "\n",
    "            results.append({\n",
    "                \"primary_id\": primary_rec[\"customer\"],\n",
    "                \"primary_name\": primary_rec[\"customer_name\"],\n",
    "                \"primary_address\": primary_rec[\"full_address\"],\n",
    "                \"secondary_id\": secondary_rec[\"customer\"],\n",
    "                \"secondary_name\": secondary_rec[\"customer_name\"],\n",
    "                \"secondary_address\": secondary_rec[\"full_address\"]\n",
    "            })\n",
    "\n",
    "            already_seen_pairs.add(pair_key)\n",
    "\n",
    "# Save results\n",
    "result_df = pd.DataFrame(results)\n",
    "result_df.to_csv(\"example_suspected_offenders.csv\", index=False)\n",
    "print(\"Finished. Matches found:\", len(result_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe2e684",
   "metadata": {},
   "source": [
    "STEP 2: USE SENTENCE TRANSFORMER TO CLASSIFY SUSPECTS AS \"NO\" (means not an offender), \"PSEUDO\" (means addresses match but names differ potentially indicating that some other family member is there) and \"COMPLETE\" (means that both names and addresses match completely)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c82ffa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 89/89 [00:05<00:00, 16.00it/s]\n",
      "Batches: 100%|██████████| 89/89 [00:03<00:00, 22.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Classification completed with improved accuracy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"HCHECK_deduplicated_offenders.csv\")\n",
    "\n",
    "# --- Helper functions ---\n",
    "def normalize_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'\\b(flat|apt|apartment|tower|block|floor|no|house|h|sec|sector|road|rd|st|street|lane|ln|plot|pl)\\b', '', text)\n",
    "    text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def normalize_name(name):\n",
    "    name = str(name).lower()\n",
    "    name = re.sub(r'[^a-z\\s]', '', name)\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    return name.split()[0] if name else \"\"  # Use first name only\n",
    "\n",
    "# Apply normalization\n",
    "df[\"primary_address_norm\"] = df[\"primary_address\"].apply(normalize_text)\n",
    "df[\"secondary_address_norm\"] = df[\"secondary_address\"].apply(normalize_text)\n",
    "df[\"primary_name_norm\"] = df[\"primary_name\"].apply(normalize_name)\n",
    "df[\"secondary_name_norm\"] = df[\"secondary_name\"].apply(normalize_name)\n",
    "\n",
    "# --- Embedding Model ---\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Generate embeddings\n",
    "address_texts = list(df[\"primary_address_norm\"]) + list(df[\"secondary_address_norm\"])\n",
    "name_texts = list(df[\"primary_name_norm\"]) + list(df[\"secondary_name_norm\"])\n",
    "\n",
    "address_embeddings = model.encode(address_texts, batch_size=64, show_progress_bar=True, normalize_embeddings=True)\n",
    "name_embeddings = model.encode(name_texts, batch_size=64, show_progress_bar=True, normalize_embeddings=True)\n",
    "\n",
    "df[\"address_score\"] = np.sum(\n",
    "    address_embeddings[:len(df)] * address_embeddings[len(df):], axis=1\n",
    ")\n",
    "df[\"name_score\"] = np.sum(\n",
    "    name_embeddings[:len(df)] * name_embeddings[len(df):], axis=1\n",
    ")\n",
    "\n",
    "# --- Classification Logic ---\n",
    "def classify(row):\n",
    "    if row[\"address_score\"] >= 0.89:\n",
    "        return \"complete\" if row[\"name_score\"] >= 0.75 else \"pseudo\"\n",
    "    elif row[\"address_score\"] >= 0.75 and row[\"name_score\"] >= 0.80:\n",
    "        return \"pseudo\"  # This is a safeguard for swapped name+address\n",
    "    else:\n",
    "        return \"no\"\n",
    "\n",
    "df[\"offender_class\"] = df.apply(classify, axis=1)\n",
    "\n",
    "# Save final output\n",
    "df[[\"primary_id\", \"primary_name\", \"primary_address\",\n",
    "    \"secondary_id\", \"secondary_name\", \"secondary_address\",\n",
    "    \"offender_class\"]].to_csv(\"example_final_verified_offenders.csv\", index=False)\n",
    "\n",
    "print(\"✓ Classification completed with improved accuracy.\")\n",
    "# This cell outputs a csv by the name final_verified_offenders in which final verified offenders are there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4144c5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offender_class\n",
      "complete    1725\n",
      "no          1043\n",
      "pseudo      1025\n",
      "Name: customer_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the final file\n",
    "df = pd.read_csv(\"example_final_verified_offenders.csv\")\n",
    "\n",
    "id_label_df = pd.concat([\n",
    "    df[[\"primary_id\", \"offender_class\"]].rename(columns={\"primary_id\": \"customer_id\"}),\n",
    "    df[[\"secondary_id\", \"offender_class\"]].rename(columns={\"secondary_id\": \"customer_id\"})\n",
    "])\n",
    "\n",
    "id_label_df = id_label_df.drop_duplicates()\n",
    "\n",
    "summary = id_label_df.groupby(\"offender_class\")[\"customer_id\"].nunique()\n",
    "\n",
    "print(summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
